{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_cleaning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPVPJp12UEaprzBgc0ShznT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harsheev/CBC_NewsArticles/blob/master/Data_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upud9HM3eojT",
        "colab_type": "text"
      },
      "source": [
        "# **This notebook goes over the process of loading in the data set, cleaning the data and creating the corpus, dictionary and text files needed to train an LDA model using gensim**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jv8VShoaEFh",
        "colab_type": "text"
      },
      "source": [
        "Setting up directory on Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgfuOy1VZt9k",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4a616394-d868-4048-e146-6a4823cea6e7"
      },
      "source": [
        "#@title Set up Directory { run: \"auto\"}\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive \n",
        "from IPython.display import clear_output\n",
        "drive.mount('/content/gdrive')\n",
        "working_directory = 'My Drive/LDA_CBC_NewsArticles' #@param {type:\"string\"}\n",
        "wd=\"/content/gdrive/\"+working_directory\n",
        "os.chdir(wd)\n",
        "\n",
        "dirpath = os.getcwd()\n",
        "print(\"current directory is : \" + dirpath)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "current directory is : /content/gdrive/My Drive/LDA_CBC_NewsArticles\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZLTiOCSatea",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "8f061cb4-92ae-43c3-bf57-08d292ef5b52"
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.23.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.14.33)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2020.6.20)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.33 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.17.33)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.33->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcbKNHJVZ8Ga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "766ea32d-f833-4c57-ad03-3d8fafca0049"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import spacy\n",
        "spacy.load('en')\n",
        "from spacy.lang.en import English\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "import random\n",
        "\n",
        "from gensim import corpora\n",
        "\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyDbLl8eZ9Bp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "19477d5d-0f91-423b-fa57-fadd06a49476"
      },
      "source": [
        "df= pd.read_csv('CA_news.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>authors</th>\n",
              "      <th>title</th>\n",
              "      <th>publish_date</th>\n",
              "      <th>description</th>\n",
              "      <th>text</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>'More vital now:' Gay-straight alliances go vi...</td>\n",
              "      <td>2020-05-03 1:30</td>\n",
              "      <td>Lily Overacker and Laurell Pallot start each g...</td>\n",
              "      <td>Lily Overacker and Laurell Pallot start each g...</td>\n",
              "      <td>https://www.cbc.ca/news/canada/calgary/gay-str...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "      <td>Scientists aim to 'see' invisible transmission...</td>\n",
              "      <td>2020-05-02 8:00</td>\n",
              "      <td>Some researchers aim to learn more about how t...</td>\n",
              "      <td>This is an excerpt from Second Opinion, a week...</td>\n",
              "      <td>https://www.cbc.ca/news/technology/droplet-tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>['The Canadian Press']</td>\n",
              "      <td>Coronavirus: What's happening in Canada and ar...</td>\n",
              "      <td>2020-05-02 11:28</td>\n",
              "      <td>Canada's chief public health officer struck an...</td>\n",
              "      <td>The latest:  The lives behind the numbers: Wha...</td>\n",
              "      <td>https://www.cbc.ca/news/canada/coronavirus-cov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[]</td>\n",
              "      <td>B.C. announces 26 new coronavirus cases, new c...</td>\n",
              "      <td>2020-05-02 18:45</td>\n",
              "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
              "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
              "      <td>https://www.cbc.ca/news/canada/british-columbi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[]</td>\n",
              "      <td>B.C. announces 26 new coronavirus cases, new c...</td>\n",
              "      <td>2020-05-02 18:45</td>\n",
              "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
              "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
              "      <td>https://www.cbc.ca/news/canada/british-columbi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Unnamed: 0  ...                                                url\n",
              "0          0  ...  https://www.cbc.ca/news/canada/calgary/gay-str...\n",
              "1          1  ...  https://www.cbc.ca/news/technology/droplet-tra...\n",
              "2          2  ...  https://www.cbc.ca/news/canada/coronavirus-cov...\n",
              "3          3  ...  https://www.cbc.ca/news/canada/british-columbi...\n",
              "4          4  ...  https://www.cbc.ca/news/canada/british-columbi...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F88curppZ86N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df= df.dropna()\n",
        "\n",
        "#changing date to datetime format\n",
        "df.publish_date= pd.to_datetime(df['publish_date'])\n",
        "#creating columns for year and month \n",
        "df['year']= df['publish_date'].dt.year\n",
        "df['month']= df['publish_date'].dt.month\n",
        "#removing articles from 2012 and 2013\n",
        "df=df[(df.year!=2013)&(df.year!=2012)]\n",
        "df.sort_values(by=['year'],inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26uOpojLZ8z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to clean out text and tokenize \n",
        "parser = English()\n",
        "def tokenize(text):\n",
        "    lda_tokens = []\n",
        "    tokens = parser(text)\n",
        "    for n in tokens:\n",
        "        if n.orth_.isspace():\n",
        "            continue\n",
        "        elif n.like_url:\n",
        "            lda_tokens.append('URL')\n",
        "        elif n.orth_.startswith('@'):\n",
        "            lda_tokens.append('SCREEN_NAME')\n",
        "        else:\n",
        "            lda_tokens.append(n.lower_)\n",
        "    return lda_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69puEy6FZ8sE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to lemmatize tokens\n",
        "def lemmatize(word):\n",
        "    lemma = wn.morphy(word)\n",
        "    if lemma is None:\n",
        "        return word\n",
        "    else:\n",
        "        return lemma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7y1MiyXZ8f7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Funtion putting together tokenization and lemmatization\n",
        "def prepare_text(text):\n",
        "    tokens = tokenize(text)\n",
        "    tokens = [token for token in tokens if len(token) > 4]\n",
        "    tokens = [token for token in tokens if token not in en_stop]\n",
        "    tokens = [lemmatize(token) for token in tokens]\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w42unhhfdjrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Apllying prepare_text() to data\n",
        "en_stop = set(nltk.corpus.stopwords.words('english')) #list of english stop words\n",
        "\n",
        "text_data=[]\n",
        "for row in df['description']:\n",
        "  tokens = prepare_text(row)\n",
        "  text_data.append(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbo-z4zwdjoj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7c3e9d0a-b458-41cb-b2ab-199460b90b85"
      },
      "source": [
        "#create dictionary -> convert to bag-of-words corpus -> save to call upon later\n",
        "\n",
        "dictionary = corpora.Dictionary(text_data)\n",
        "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
        "pickle.dump(text_data, open('text_data.pkl', 'wb'))\n",
        "pickle.dump(corpus, open('corpus_test.pkl', 'wb'))\n",
        "dictionary.save('dictionary_test.gensim')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJwmrgAAeKDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}